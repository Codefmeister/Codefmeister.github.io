<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>点云配准 on Codefmeister</title>
    <link>https://codefmeister.github.io/tags/%E7%82%B9%E4%BA%91%E9%85%8D%E5%87%86/</link>
    <description>Recent content in 点云配准 on Codefmeister</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://codefmeister.github.io/tags/%E7%82%B9%E4%BA%91%E9%85%8D%E5%87%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FCGF论文阅读笔记</title>
      <link>https://codefmeister.github.io/p/fcgf%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://codefmeister.github.io/p/fcgf%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>0. Abstract 从三维点云或者扫描帧中提取出几何特征是许多任务例如配准，场景重建等的第一步。现有的领先的方法都是将low-level的特征作为输入，或者在有限的感受野上提取得到基于patch的特征。本文提出的是一个全卷积几何特征提取网络，名为fully-convolutional geometric features。 通过一个3D的全卷积网络的一次pass，即可得到几何特征。 同时提出了一个新的度量学习的loss函数，可以显著的提高网络的性能。 FCGF的几何特征十分紧凑，可以捕捉广阔的上下文空间，并缩放到大型场景中。在室内（3D Match）和室外（KITTI）数据集上进行验证的结果显示，其达到了state-of-art的精确率，而且并不需要数据的预处理，并且很紧凑（32维的特征），比其余最精确的方法快290倍。
1. Introduction 寻找几何意义上的点对关系是很多三维任务十分重要的一步。因此，大量的工作集中于设计三维特征，以捕捉具有可判别性的局部几何机构，来建立点对关系。
基于学习的三维特征由于其鲁棒性与出色的性能表现，在最近得到了广泛的关注。现有的基于学习的特征提取工作大都依赖于低阶的几何特征作为输入，例如角度偏差，点的分布，或者体积距离函数等。随后，对每个兴趣点(point of interest)提取一个三维patch，然后通过多层感知机或者三维卷积层将之映射到一个低维的特征空间。这个过程计算代价高昂，而且只能够提取得到降采样后兴趣点处的特征，因此会降低后续配准步骤中的空间分辨率。
上述的基于patch的处理过程效率很低，因为其中间网络的激活结果并没有在相邻的patch上进行复用。用2D卷积进行类比，对某个兴趣点提取其三维patch与对某个像素块提取其周围的一个像素patch类似。不仅如此，现有的pipeline仅局限于对空间范围有限的patch进行卷积，限制了空间语境的解读。
不同于上文所述，我们应用一个可以作用于整个输入的三维卷积操作，而不需要裁剪片段，该操作是通过将卷积转换为全卷积的子项来完成的（convolution组装得到一个fully convolution）。 相似的，我们将MLP中的全连接层用一系列卷积层来替代，其卷积核的size为1x1x1。 全卷积网络与非全卷积网络相比，可以捕捉更广阔的上下文，更快，内存效率更高。其原因在于中间的激活结果在重叠的区域上进行了复用。
尽管有这些优势，全卷积网络因为三维数据的(一些)特点并未在三维特征提取中得到广泛的应用。一个对三维数据进行卷积的卷积网络的标准输入代表是一个稠密的四维tensor，其中三维是空间维度，还有一个特征维。这种表示方式对内存消耗很大，很多voxel都是空的。
在本文的工作中，采用了一种稀疏的tensor表示法。同时，针对全卷积上的度量学习，提出了一个新的loss函数。因为观察到全卷积特征不同于传统的度量学习的假设，传统的度量学习由于锚点都是随机采样的，所以假设样本是独立同分布的，而在全卷积网络中，相邻的点的特征是高度相关的。并不符合独立同分布的假设，所以需要重新设计loss函数。同时，该方法并不需要对数据进行低阶的预处理，或者提取三维patch，可以快速的生成高分辨率的， 具有state-of-art的判别潜力的特征。
FCGF在室内室外数据集上均进行了测试，可以达到state-of-art的性能表现，比最快的快9倍，比最好的快290倍。
2. Related Work Hand-craft 3D feature：早期对三维特征的描述集中在手工的，能够有区别的（有基于feature鉴别的潜力 discriminatively）的对局部几何特征进行刻画的描述符。Spin Images [16] use a projection of adjacent points onto the tangent plane. USC [29] uses covariance matrices of point pairs. SHOT [26] creates a 3D histogram of normal vectors. PFH [24] and FPFH [23] build an oriented histogram using pairwise geometric properties.</description>
    </item>
    
    <item>
      <title>Learning Multiview 3D point Cloud Registration</title>
      <link>https://codefmeister.github.io/p/learning-multiview-3d-point-cloud-registration/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://codefmeister.github.io/p/learning-multiview-3d-point-cloud-registration/</guid>
      <description>Learning multiview 3D point cloud registration Abstract 提出了一种全新的，端到端的，可学习的多视角三维点云配准算法。 多视角配准往往需要两个阶段：第一个阶段进行初始化配准，给定点云各帧之间两两的初始化刚体变换关系；第二个阶段在全局意义上进行不断精细化处理。前者往往由于点云之间的低重叠率，对称性，或者重复的场景片段而导致配准精度较差。因此，紧随其后的全局优化（Global Refinement）的目标就是在多个点云帧中建立一种循环一致性(cyclic consistency).
而此文章提出了一种算法，将两个阶段融合在一起进行端对端的交替学习。在公认的基准数据集上的实验评估表明，其方法显著优于state-of-art，而且又是端到端可训练的，所需要的计算资源也更少。此外，其还进行了详细的分析和烧蚀试验去验证其方法的novel part.
1. Introduction 三维计算机视觉的下游任务，如语义分割和目标检测，通常需要场景的整体表示。因此，将仅覆盖环境一小部分的单个点云配准和融合为一个全局一致的完整表示的能力是十分重要的，而且在增强现实和机器人技术中有着不少用例。相邻片段之间的双视角配准是一个被深入研究过的问题，传统的基于几何约束[51, 66, 56] 和手工设计的特征描述符[37, 27, 54, 69]的配准方法在某种程度上取得了成功。然而， 近些年，用于双视角三维点云配准的局部描述符的研究聚焦于深度学习方法[67: 3DMatch, 38, 21: Ppfnet, 64, 19: Ppf-foldnet, 28: perfect match]，这些方法成功捕捉并编码了隐藏在手工特征符下的证据。在此基础上，一些全新的端到端的双视角点云配准方法最近被提出[62: DCP, 42: Deepvcp]。 虽然双视角配准在很多任务中展现出了不错的性能，但对场景中的多个点云帧进行配准时，其存在一些概念上的缺陷：(1) 相邻点云之间的低重合率会导致不精确或者错误的匹配。(2) 点云配准必须依赖于非常局部的特征，对于3D场景结构简单或者重复结构较多的情况十分有害。(3)在两两配准之后，需要进行单独的处理来将所有双视角配准结果组合为一个全局表示。与双视角配准相比，应用于无组织的点云片段上的全局一致的多视角配准方法能够更充分的从深度学习技术取得的进步中获益。 现有的领先方法仍然常常依赖于双视角映射的良好初始化（良好的初值），然后再在后续的步骤中通过一系列解耦的步骤进行全局优化。这种分层处理的一大缺点在于，姿态图所有节点上的全局噪声分布在配准结束后远不是随机的。也就是说，由于配准结果和初始的双视角映射高度相关，会存在着不可忽视的误差。
在这篇论文中，作者提出了第一个端到端的，数据驱动的多视角点云配准算法。其方法以可能存在重叠关系的点云集合为输入，对每个点云帧输出一个刚体变换矩阵。我们从传统的两阶段方法中跳脱出来，让各个阶段彼此分离，直接学习以一种全局一致的方式对所有点云帧进行配准。
其工作的主要贡献在于：
  将传统的两阶段方法用端到端的神经网络的方式阐述，在其前传过程中，主要解决了两个可微分的最优化问题：(i)对两两点云之间刚体变换参数估计的Procrustes问题。(ii) 刚体变换同步的谱松弛(spectral relaxation)问题
  提出了一个置信度估计模块，其使用了一个新颖的overlap pooling layer重叠池化层来预测估算得到的双视角刚体变换参数的可信度。
  将多视角三维点云配准问题转换为迭代重加权最小二乘问题(IRLS)，迭代地优化两两配准之间的刚体变换估计和绝对坐标意义下的刚体变换估计（全局）。
  因为以上所提到的工作，所提出的多视角点云配准算法是(i) 计算效率很高 (ii) 可以达到更加精确的配准结果，因为残差会以一种迭代的方式被送回双视角配准网络中去。 (iii)不论是双视角配准还是多视角配准，都比现有的方法的精度要高，效果要好。
2. Related Work Pairwise registration: 传统的双视角配准pipeline包含两个阶段： the coarse alignment stage（粗配准）， 为相对刚体变换参数提供一个初始估计；the refinement stage 通过迭代最小化配准误差，不断优化刚体变换参数。</description>
    </item>
    
    <item>
      <title>DCP论文阅读笔记</title>
      <link>https://codefmeister.github.io/p/dcp%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://codefmeister.github.io/p/dcp%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>DCP论文阅读笔记 论文  Deep Closest Point: Learning Representations for Point Cloud Registration
Author: Wang, Yue; Solomon, Justin
 Main Attribution 基于ICP迭代最近点算法，提出基于深度学习的DCP算法。解决了ICP想要采用深度学习方法时遇到的一系列问题。
我们先回顾一下ICP算法的基本步骤：
for each iteration: find corresponding relations of points between two scan(using KNN) using SVD to solve Rotation Matrix and Translation vector update cloud Data 概括起来就是： 寻找最近点对关系，使用SVD求解刚体变换。如此循环往复。
结合论文，个人理解将ICP算法扩展到深度学习存在着以下的难点（可能存在各种问题，笔者深度学习的相关知识很薄弱）：
 首先，点对关系如果是确定的话，沿着网络反向传播可能存在问题。 SVD分解求解刚体变换，如何求梯度？(Confirmed by paper)  而文章克服了这些问题，主要有如下贡献：
 提出了能够解决传统ICP算法试图推广时存在的困难的一系列子网络架构。 提出了能进行pair-wise配准的网络架构 评估了在采用不同设置的情况下的网络表现 分析了是global feature有用还是local feature对配准更加有用  网络架构 模型包含三个部分：
(1) 一个将输入点云映射到高维空间embedding的模块，具有扰动不变性（指DGCNN当点云输入时点的前后顺序发生变化，输出不会有任何改变） 或者 刚体变换不变性（指PointNet对于旋转平移具有不变的特性）。该模块的作用是寻找两个输入点云之间的点的对应关系. 可选的模块有PointNet（Focus于全局特征）， DGCNN（结合局部特征和全局特征）。</description>
    </item>
    
    <item>
      <title>DGCNN论文解读</title>
      <link>https://codefmeister.github.io/p/dgcnn%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Mon, 21 Dec 2020 09:40:49 +0800</pubDate>
      
      <guid>https://codefmeister.github.io/p/dgcnn%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>DGCNN 前言 因为关心的领域主要是配准，对于分类等网络的架构设计分析并没有侧重太多，主要侧重的是EdgeConv的思想。
论文  Dynamic Graph CNN for Learning on Point Clouds, Wang, Yue and Sun, Yongbin.
 核心思想:关于EdgeConv 将点云表征为一个图，${\rm{G}}(V,\xi )$ ,点云的每一个点对应图中的一个结点，而图中的每一条边对应的是点之间的特征feature，称为Edge-feature。举个例子，最简单的情景，可以通过KNN来构建图。Edge Feature用$e_{ij}$来表示，定义为： $$ e_{ij} = h_{\Theta}(x_i,x_j) $$ $$ h_{\Theta}: {R^F} \times {R^F} \to {R^{F&#39;}} $$ $h_{\Theta}$是一个非线性的映射，拥有一系列可学习的参数。
提出了一个名为EdgeConv的神经网络模块Module，该模块基于卷积神经网络，可以适应在点云上的高阶任务。EdgeConv的对于第i个顶点的输出为：
其中$□$代表的是一个对称聚合函数，如$\Sigma, max$。
可以将上述描述类比为在图像上的卷积操作。我们把$x_i$看作是中心像素点，而$x_j:(i,j) \in \xi$可以看做是围绕在点$x_i$周围的像素($x_j$事实上就是和$x_i$之间存在着feature edge的点）。所以类比这样的卷积操作，Edge-Conv可以将n个点的$F$维点云通过“卷积”转换为具有n个点的$F&#39;$维的点云。 所以选择$h$和$□$就变得十分关键。它会直接影响EdgeConv的性能特性。
一些其他的选择在下一个小part中讨论。在本文中，作者采用的： $$ h_{\Theta}(x_i,x_j) = {\bar h}_{\Theta}(x_i, x_j - x_i) $$
从这个表达式可以非常明显的看出，既结合了全局形状结构，也结合了局部的结构信息。Global shape structure通过$x_i$捕捉，local neighborhood information通过$x_j - x_i$来捕捉。
更具体一点的说，通过如下两个公式来计算edge_feature以及x&#39;： $$ e_{ijm}&#39; = ReLU(\theta_m \cdot(x_j - x_i) + \phi_m \cdot x_i) $$ $$ x_{im}&#39; = \mathop {\max }\limits_{j:(i,j) \in \xi }e_{ijm}&#39; $$</description>
    </item>
    
    <item>
      <title>MATrICP论文解读</title>
      <link>https://codefmeister.github.io/p/matricp%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Thu, 03 Dec 2020 09:40:49 +0800</pubDate>
      
      <guid>https://codefmeister.github.io/p/matricp%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>MATrICP 论文  Improved techniques for multi-view registration with motion averaging
Li, Zhongyu Zhu, Jihua Lan, Ke Li, Chen Fang, Chaowei
 核心思想 将Trimmed ICP与运动平均算法结合起来，应用到多视角聚类上。
算法步骤 1. 估算各帧之间的重叠百分比$\xi_{i,j}$ 总的来说，估算各帧之间的重叠百分比主要分为两步：
(1) 对于每一帧，计算其$d_{threshold}$
(2) 计算出每一帧的$d_{threshold}$之后，使用该参数计算该帧与其他帧的重叠百分比。
1.0 背景知识 ObjFunc：
1.1 计算$d_{threshold}$ 对于第i帧的每一个点，可以在其他所有帧中寻找到N-1个对应点（通过NN），假设第i帧有$N_i$个点，那么一共会有$N_i * (N-1)$个点对与距离。因为我们是要进行多视角配准的，相当于把当前帧作为源scan，其他所有帧组成的模型作为目标模板进行配准。所以将这些所有距离按照从小到大进行排序，然后依次对于每一个距离，计算该距离以及之前所有距离对应的ObjectFunction值。可以使用cumsum操作。结果是得到同样长度的ObjectFunction值的数组，取其中的最小值，该目标函数最小值对应着一个距离$d_i$，这个距离$d_i$就可以作为第i帧的$d_{threshold}$，用于第i帧与其他帧（第j帧）的重叠率估算。
1.2 计算第i帧与其他帧的重叠百分比 对于第$i$帧，我们现在有其$d_{threshold}$。那么求$\xi_{i,j}$，即为：使用NN寻找点对pair$(P_i,P_j)$，然后从小到大排列，取$d &amp;lt; d_{threshold}$的部分。假设有$N_j^{&#39;}$个点对满足要求。那么重叠百分比$\xi_{i,j} = N_j^{&#39;} / N_j$，$N_j$为第j帧的点。
2. 根据估算得到的${\xi_{i,j}}$，选择重叠率高的scan pair，应用TrICP算法求解其relative Motion $M_{i,j}$ 2. 应用运动平均算法 在应用Motion Average前，我们已经有了初始的Global Motion以及一系列Relative Motion。
运动平均的主要思想是，将relative Motion看作是global Motion的某种组合。先求出$\Delta M_{i,j}$，将其转换为李代数对应的6x1的向量。然后通过Average的思想，求出global Motion的变化值。
2.1 计算relative motion $M_{i,j}$的变化值 通过global motion，可以求出$\Delta M_{i,j}$ $$ \Delta M_{i,j} = M_i^0 M_{i,j} {(M_j^0)}^{-1} $$</description>
    </item>
    
  </channel>
</rss>
