<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>点云配准 on Codefmeister</title>
    <link>https://codefmeister.github.io/tags/%E7%82%B9%E4%BA%91%E9%85%8D%E5%87%86/</link>
    <description>Recent content in 点云配准 on Codefmeister</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://codefmeister.github.io/tags/%E7%82%B9%E4%BA%91%E9%85%8D%E5%87%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning Multiview 3D point Cloud Registration</title>
      <link>https://codefmeister.github.io/p/learning-multiview-3d-point-cloud-registration/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://codefmeister.github.io/p/learning-multiview-3d-point-cloud-registration/</guid>
      <description>Learning multiview 3D point cloud registration Abstract 提出了一种全新的，端到端的，可学习的多视角三维点云配准算法。 多视角配准往往需要两个阶段：第一个阶段进行初始化配准，给定点云各帧之间两两的初始化刚体变换关系；第二个阶段在全局意义上进行不断精细化处理。前者往往由于点云之间的低重叠率，对称性，或者重复的场景片段而导致配准精度较差。因此，紧随其后的全局优化（Global Refinement）的目标就是在多个点云帧中建立一种循环一致性(cyclic consistency).
而此文章提出了一种算法，将两个阶段融合在一起进行端对端的交替学习。在公认的基准数据集上的实验评估表明，其方法显著优于state-of-art，而且又是端到端可训练的，所需要的计算资源也更少。此外，其还进行了详细的分析和烧蚀试验去验证其方法的novel part.
1. Introduction 三维计算机视觉的下游任务，如语义分割和目标检测，通常需要场景的整体表示。因此，将仅覆盖环境一小部分的单个点云配准和融合为一个全局一致的完整表示的能力是十分重要的，而且在增强现实和机器人技术中有着不少用例。相邻片段之间的双视角配准是一个被深入研究过的问题，传统的基于几何约束[51, 66, 56] 和手工设计的特征描述符[37, 27, 54, 69]的配准方法在某种程度上取得了成功。然而， 近些年，用于双视角三维点云配准的局部描述符的研究聚焦于深度学习方法[67: 3DMatch, 38, 21: Ppfnet, 64, 19: Ppf-foldnet, 28: perfect match]，这些方法成功捕捉并编码了隐藏在手工特征符下的证据。在此基础上，一些全新的端到端的双视角点云配准方法最近被提出[62: DCP, 42: Deepvcp]。 虽然双视角配准在很多任务中展现出了不错的性能，但对场景中的多个点云帧进行配准时，其存在一些概念上的缺陷：(1) 相邻点云之间的低重合率会导致不精确或者错误的匹配。(2) 点云配准必须依赖于非常局部的特征，对于3D场景结构简单或者重复结构较多的情况十分有害。(3)在两两配准之后，需要进行单独的处理来将所有双视角配准结果组合为一个全局表示。与双视角配准相比，应用于无组织的点云片段上的全局一致的多视角配准方法能够更充分的从深度学习技术取得的进步中获益。 现有的领先方法仍然常常依赖于双视角映射的良好初始化（良好的初值），然后再在后续的步骤中通过一系列解耦的步骤进行全局优化。这种分层处理的一大缺点在于，姿态图所有节点上的全局噪声分布在配准结束后远不是随机的。也就是说，由于配准结果和初始的双视角映射高度相关，会存在着不可忽视的误差。
在这篇论文中，作者提出了第一个端到端的，数据驱动的多视角点云配准算法。其方法以可能存在重叠关系的点云集合为输入，对每个点云帧输出一个刚体变换矩阵。我们从传统的两阶段方法中跳脱出来，让各个阶段彼此分离，直接学习以一种全局一致的方式对所有点云帧进行配准。
其工作的主要贡献在于：
  将传统的两阶段方法用端到端的神经网络的方式阐述，在其前传过程中，主要解决了两个可微分的最优化问题：(i)对两两点云之间刚体变换参数估计的Procrustes问题。(ii) 刚体变换同步的谱松弛(spectral relaxation)问题
  提出了一个置信度估计模块，其使用了一个新颖的overlap pooling layer重叠池化层来预测估算得到的双视角刚体变换参数的可信度。
  将多视角三维点云配准问题转换为迭代重加权最小二乘问题(IRLS)，迭代地优化两两配准之间的刚体变换估计和绝对坐标意义下的刚体变换估计（全局）。
  因为以上所提到的工作，所提出的多视角点云配准算法是(i) 计算效率很高 (ii) 可以达到更加精确的配准结果，因为残差会以一种迭代的方式被送回双视角配准网络中去。 (iii)不论是双视角配准还是多视角配准，都比现有的方法的精度要高，效果要好。
2. Related Work Pairwise registration: 传统的双视角配准pipeline包含两个阶段： the coarse alignment stage（粗配准）， 为相对刚体变换参数提供一个初始估计；the refinement stage 通过迭代最小化配准误差，不断优化刚体变换参数。</description>
    </item>
    
    <item>
      <title>DCP论文阅读笔记</title>
      <link>https://codefmeister.github.io/p/dcp%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://codefmeister.github.io/p/dcp%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>DCP论文阅读笔记 论文  Deep Closest Point: Learning Representations for Point Cloud Registration
Author: Wang, Yue; Solomon, Justin
 Main Attribution 基于ICP迭代最近点算法，提出基于深度学习的DCP算法。解决了ICP想要采用深度学习方法时遇到的一系列问题。
我们先回顾一下ICP算法的基本步骤：
for each iteration: find corresponding relations of points between two scan(using KNN) using SVD to solve Rotation Matrix and Translation vector update cloud Data 概括起来就是： 寻找最近点对关系，使用SVD求解刚体变换。如此循环往复。
结合论文，个人理解将ICP算法扩展到深度学习存在着以下的难点（可能存在各种问题，笔者深度学习的相关知识很薄弱）：
 首先，点对关系如果是确定的话，沿着网络反向传播可能存在问题。 SVD分解求解刚体变换，如何求梯度？(Confirmed by paper)  而文章克服了这些问题，主要有如下贡献：
 提出了能够解决传统ICP算法试图推广时存在的困难的一系列子网络架构。 提出了能进行pair-wise配准的网络架构 评估了在采用不同设置的情况下的网络表现 分析了是global feature有用还是local feature对配准更加有用  网络架构 模型包含三个部分：
(1) 一个将输入点云映射到高维空间embedding的模块，具有扰动不变性（指DGCNN当点云输入时点的前后顺序发生变化，输出不会有任何改变） 或者 刚体变换不变性（指PointNet对于旋转平移具有不变的特性）。该模块的作用是寻找两个输入点云之间的点的对应关系. 可选的模块有PointNet（Focus于全局特征）， DGCNN（结合局部特征和全局特征）。</description>
    </item>
    
    <item>
      <title>DGCNN论文解读</title>
      <link>https://codefmeister.github.io/p/dgcnn%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Mon, 21 Dec 2020 09:40:49 +0800</pubDate>
      
      <guid>https://codefmeister.github.io/p/dgcnn%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>DGCNN 前言 因为关心的领域主要是配准，对于分类等网络的架构设计分析并没有侧重太多，主要侧重的是EdgeConv的思想。
论文  Dynamic Graph CNN for Learning on Point Clouds, Wang, Yue and Sun, Yongbin.
 核心思想:关于EdgeConv 将点云表征为一个图，${\rm{G}}(V,\xi )$ ,点云的每一个点对应图中的一个结点，而图中的每一条边对应的是点之间的特征feature，称为Edge-feature。举个例子，最简单的情景，可以通过KNN来构建图。Edge Feature用$e_{ij}$来表示，定义为： $$ e_{ij} = h_{\Theta}(x_i,x_j) $$ $$ h_{\Theta}: {R^F} \times {R^F} \to {R^{F&#39;}} $$ $h_{\Theta}$是一个非线性的映射，拥有一系列可学习的参数。
提出了一个名为EdgeConv的神经网络模块Module，该模块基于卷积神经网络，可以适应在点云上的高阶任务。EdgeConv的对于第i个顶点的输出为：
其中$□$代表的是一个对称聚合函数，如$\Sigma, max$。
可以将上述描述类比为在图像上的卷积操作。我们把$x_i$看作是中心像素点，而$x_j:(i,j) \in \xi$可以看做是围绕在点$x_i$周围的像素($x_j$事实上就是和$x_i$之间存在着feature edge的点）。所以类比这样的卷积操作，Edge-Conv可以将n个点的$F$维点云通过“卷积”转换为具有n个点的$F&#39;$维的点云。 所以选择$h$和$□$就变得十分关键。它会直接影响EdgeConv的性能特性。
一些其他的选择在下一个小part中讨论。在本文中，作者采用的： $$ h_{\Theta}(x_i,x_j) = {\bar h}_{\Theta}(x_i, x_j - x_i) $$
从这个表达式可以非常明显的看出，既结合了全局形状结构，也结合了局部的结构信息。Global shape structure通过$x_i$捕捉，local neighborhood information通过$x_j - x_i$来捕捉。
更具体一点的说，通过如下两个公式来计算edge_feature以及x&#39;： $$ e_{ijm}&#39; = ReLU(\theta_m \cdot(x_j - x_i) + \phi_m \cdot x_i) $$ $$ x_{im}&#39; = \mathop {\max }\limits_{j:(i,j) \in \xi }e_{ijm}&#39; $$</description>
    </item>
    
    <item>
      <title>MATrICP论文解读</title>
      <link>https://codefmeister.github.io/p/matricp%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Thu, 03 Dec 2020 09:40:49 +0800</pubDate>
      
      <guid>https://codefmeister.github.io/p/matricp%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>MATrICP 论文  Improved techniques for multi-view registration with motion averaging
Li, Zhongyu Zhu, Jihua Lan, Ke Li, Chen Fang, Chaowei
 核心思想 将Trimmed ICP与运动平均算法结合起来，应用到多视角聚类上。
算法步骤 1. 估算各帧之间的重叠百分比$\xi_{i,j}$ 总的来说，估算各帧之间的重叠百分比主要分为两步：
(1) 对于每一帧，计算其$d_{threshold}$
(2) 计算出每一帧的$d_{threshold}$之后，使用该参数计算该帧与其他帧的重叠百分比。
1.0 背景知识 ObjFunc：
1.1 计算$d_{threshold}$ 对于第i帧的每一个点，可以在其他所有帧中寻找到N-1个对应点（通过NN），假设第i帧有$N_i$个点，那么一共会有$N_i * (N-1)$个点对与距离。因为我们是要进行多视角配准的，相当于把当前帧作为源scan，其他所有帧组成的模型作为目标模板进行配准。所以将这些所有距离按照从小到大进行排序，然后依次对于每一个距离，计算该距离以及之前所有距离对应的ObjectFunction值。可以使用cumsum操作。结果是得到同样长度的ObjectFunction值的数组，取其中的最小值，该目标函数最小值对应着一个距离$d_i$，这个距离$d_i$就可以作为第i帧的$d_{threshold}$，用于第i帧与其他帧（第j帧）的重叠率估算。
1.2 计算第i帧与其他帧的重叠百分比 对于第$i$帧，我们现在有其$d_{threshold}$。那么求$\xi_{i,j}$，即为：使用NN寻找点对pair$(P_i,P_j)$，然后从小到大排列，取$d &amp;lt; d_{threshold}$的部分。假设有$N_j^{&#39;}$个点对满足要求。那么重叠百分比$\xi_{i,j} = N_j^{&#39;} / N_j$，$N_j$为第j帧的点。
2. 根据估算得到的${\xi_{i,j}}$，选择重叠率高的scan pair，应用TrICP算法求解其relative Motion $M_{i,j}$ 2. 应用运动平均算法 在应用Motion Average前，我们已经有了初始的Global Motion以及一系列Relative Motion。
运动平均的主要思想是，将relative Motion看作是global Motion的某种组合。先求出$\Delta M_{i,j}$，将其转换为李代数对应的6x1的向量。然后通过Average的思想，求出global Motion的变化值。
2.1 计算relative motion $M_{i,j}$的变化值 通过global motion，可以求出$\Delta M_{i,j}$ $$ \Delta M_{i,j} = M_i^0 M_{i,j} {(M_j^0)}^{-1} $$</description>
    </item>
    
  </channel>
</rss>
