<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='æœ¬æ–‡å‚è€ƒ lr_schedulerä»‹ç» ä»¥åŠ PyTorch optimæ–‡æ¡£
 1 æ¦‚è¿° 1.1 PyTorchæ–‡æ¡£ï¼štorch.optimè§£è¯»  ä¸‹å›¾æ˜¯optimçš„æ–‡æ¡£
  TORCH.OPTIM torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future.
 torch.optimç®€ä»‹
torch.optimæ˜¯PyTorchå®ç°çš„ä¸€ä¸ªåŒ…ï¼Œé‡Œé¢æœ‰å„ç§å„æ ·çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¤§éƒ¨åˆ†å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•éƒ½å·²ç»è¢«æ”¯æŒï¼Œæ¥å£ä¹Ÿååˆ†é€šç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥é›†æˆå®ç°æ›´åŠ å¤æ‚çš„ç³»ç»Ÿã€‚
 How to use an optimizer To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.'><title>torch.optimè§£è¯»</title>

<link rel='canonical' href='https://codefmeister.github.io/p/torch.optim%E8%A7%A3%E8%AF%BB/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='torch.optimè§£è¯»'>
<meta property='og:description' content='æœ¬æ–‡å‚è€ƒ lr_schedulerä»‹ç» ä»¥åŠ PyTorch optimæ–‡æ¡£
 1 æ¦‚è¿° 1.1 PyTorchæ–‡æ¡£ï¼štorch.optimè§£è¯»  ä¸‹å›¾æ˜¯optimçš„æ–‡æ¡£
  TORCH.OPTIM torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future.
 torch.optimç®€ä»‹
torch.optimæ˜¯PyTorchå®ç°çš„ä¸€ä¸ªåŒ…ï¼Œé‡Œé¢æœ‰å„ç§å„æ ·çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¤§éƒ¨åˆ†å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•éƒ½å·²ç»è¢«æ”¯æŒï¼Œæ¥å£ä¹Ÿååˆ†é€šç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥é›†æˆå®ç°æ›´åŠ å¤æ‚çš„ç³»ç»Ÿã€‚
 How to use an optimizer To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.'>
<meta property='og:url' content='https://codefmeister.github.io/p/torch.optim%E8%A7%A3%E8%AF%BB/'>
<meta property='og:site_name' content='Codefmeister'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='PyTorch' /><meta property='article:published_time' content='2020-11-21T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2020-11-21T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="torch.optimè§£è¯»">
<meta name="twitter:description" content="æœ¬æ–‡å‚è€ƒ lr_schedulerä»‹ç» ä»¥åŠ PyTorch optimæ–‡æ¡£
 1 æ¦‚è¿° 1.1 PyTorchæ–‡æ¡£ï¼štorch.optimè§£è¯»  ä¸‹å›¾æ˜¯optimçš„æ–‡æ¡£
  TORCH.OPTIM torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future.
 torch.optimç®€ä»‹
torch.optimæ˜¯PyTorchå®ç°çš„ä¸€ä¸ªåŒ…ï¼Œé‡Œé¢æœ‰å„ç§å„æ ·çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¤§éƒ¨åˆ†å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•éƒ½å·²ç»è¢«æ”¯æŒï¼Œæ¥å£ä¹Ÿååˆ†é€šç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥é›†æˆå®ç°æ›´åŠ å¤æ‚çš„ç³»ç»Ÿã€‚
 How to use an optimizer To use torch.optim you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.">
    </head>
    <body class="">
        <div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar">
            <aside class="sidebar left-sidebar sticky">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header class="site-info">
        
            <figure class="site-avatar">
                
                    
                    
                    
                        
                        <img src="/img/Icon_hua25ec96b536dfdbbcc947accbc1cb594_86128_300x0_resize_q75_box.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                

                
                    <span class="emoji">ğŸ¥</span>
                
            </figure>
        
        <h1 class="site-name"><a href="https://codefmeister.github.io">Codefmeister</a></h1>
        <h2 class="site-description">Major in Computer science</h2>
    </header>

    <ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/about'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/archives'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/search'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
    </ol>
</aside>

            <main class="main full-width">
    <div id="article-toolbar">
        <a href="https://codefmeister.github.io" class="back-home">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



            <span>Back</span>
        </a>
    </div>

    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <h2 class="article-title">
        <a href="/p/torch.optim%E8%A7%A3%E8%AF%BB/">torch.optimè§£è¯»</a>
    </h2>

    <footer class="article-time">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <time class="article-time--published">Nov 21, 2020</time>
    </footer></div>
</header>

    <section class="article-content">
    <blockquote>
<p>æœ¬æ–‡å‚è€ƒ
<a class="link" href="https://blog.csdn.net/qyhaill/article/details/103043637"  target="_blank" rel="noopener"
    >lr_schedulerä»‹ç»</a> ä»¥åŠ
<a class="link" href="https://pytorch.org/docs/stable/optim.html"  target="_blank" rel="noopener"
    >PyTorch optimæ–‡æ¡£</a></p>
</blockquote>
<h1 id="1-æ¦‚è¿°">1 æ¦‚è¿°</h1>
<h2 id="11-pytorchæ–‡æ¡£torchoptimè§£è¯»">1.1 PyTorchæ–‡æ¡£ï¼štorch.optimè§£è¯»</h2>
<blockquote>
<p>ä¸‹å›¾æ˜¯optimçš„æ–‡æ¡£</p>
</blockquote>
<blockquote>
<h4 id="torchoptim">TORCH.OPTIM</h4>
<p><code>torch.optim</code> is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future.</p>
</blockquote>
<p><strong>torch.optimç®€ä»‹</strong><br>
torch.optimæ˜¯PyTorchå®ç°çš„ä¸€ä¸ªåŒ…ï¼Œé‡Œé¢æœ‰å„ç§å„æ ·çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¤§éƒ¨åˆ†å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•éƒ½å·²ç»è¢«æ”¯æŒï¼Œæ¥å£ä¹Ÿååˆ†é€šç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç”¨æ¥é›†æˆå®ç°æ›´åŠ å¤æ‚çš„ç³»ç»Ÿã€‚</p>
<blockquote>
<h4 id="how-to-use-an-optimizer">How to use an optimizer</h4>
<p>To use <code>torch.optim</code> you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients.</p>
</blockquote>
<p><strong>å¦‚ä½•ä½¿ç”¨PyTorchæä¾›çš„optimizer</strong><br>
é€šè¿‡<code>torch.optim</code>æ¥åˆ›å»ºä¸€ä¸ª<code>Optimizer</code>å¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡ä¸­ä¼šä¿å­˜å½“å‰çš„çŠ¶æ€ï¼Œå¹¶ä¸”ä¼šæ ¹æ®è®¡ç®—çš„æ¢¯åº¦å€¼æ›´æ–°å‚æ•°ã€‚</p>
<blockquote>
<h4 id="constructing-it">Constructing it</h4>
<p>To construct an <code>Optimizer</code> you have to give it an iterable containing the parameters (all should be <code>Variables</code>) to optimize. Then, you can specify optimizer-specific options such as the learning rate, weight decay, etc.</p>
<blockquote>
<h5 id="note">NOTE</h5>
<p>If you need to move a model to GPU via <code>.cuda()</code>, please do so before constructing optimizers for it. Parameters of a model after <code>.cuda()</code> will be different objects with those before the call.     <br>
In general, you should make sure that optimized parameters live in consistent locations when optimizers are constructed and used.</p>
</blockquote>
</blockquote>
<p><strong>æ„é€ Optimizer</strong><br>
æ„é€ <code>Optimizer</code>æ—¶ï¼Œéœ€è¦ä¼ å…¥ä¸€ä¸ªåŒ…å«éœ€è¦è¿›è¡Œä¼˜åŒ–çš„æ‰€æœ‰å‚æ•°çš„<code>iterable</code>å¯¹è±¡ï¼Œæ‰€æœ‰å‚æ•°éƒ½å¿…é¡»æ˜¯<code>Variables</code>ç±»å‹ã€‚éšåå¯ä»¥è¿›ä¸€æ­¥è®¾ç½®optimizerçš„å…¶ä»–å…·ä½“å‚æ•°ï¼Œå¦‚learning rate, weight decay, etc.<br>
<strong>æ³¨æ„</strong>:<br>
å¦‚æœéœ€è¦å°†æ¨¡å‹ç§»åˆ°cudaä¸Š(é€šè¿‡<code>.cuda</code>å‘½ä»¤)ï¼Œé‚£ä¹ˆå¿…é¡»å…ˆç§»åŠ¨æ¨¡å‹ï¼Œå†å¯¹æ¨¡å‹æ„é€ <code>optimizer</code>ã€‚å› ä¸ºè°ƒç”¨<code>.cuda</code>å‰çš„æ¨¡å‹å‚æ•°ä¸è°ƒç”¨<code>.cuda</code>åçš„æ¨¡å‹å‚æ•°ä¸åŒã€‚<br>
é€šå¸¸æ¥è®²ï¼Œåœ¨ä½¿ç”¨<code>Optimizer</code>å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œéœ€è¦ä¿è¯æ„é€ å’Œä½¿ç”¨æ—¶ï¼Œè¢«ä¼˜åŒ–çš„å‚æ•°ä¿å­˜åœ¨åŒä¸€ä½ç½®ã€‚</p>
<p>ä»¥ä¸‹æ˜¯å®ä¾‹ï¼š</p>
<blockquote>
<p>Example:</p>
<pre><code>optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
optimizer = optim.Adam([var1, var2], lr=0.0001)
</code></pre></blockquote>
<blockquote>
<h4 id="per-parameter-options">Per-parameter options</h4>
<p><code>Optimizer</code>s also support specifying per-parameter options. To do this, instead of passing an iterable of <code>Variable</code>s, pass in an iterable of <code>dict</code>s. Each of them will define a separate parameter group, and should contain a params key, containing a list of parameters belonging to it. Other keys should match the keyword arguments accepted by the optimizers, and will be used as optimization options for this group.</p>
<blockquote>
<h5 id="note-1">NOTE</h5>
<p>You can still pass options as keyword arguments. They will be used as defaults, in the groups that didn&rsquo;t override them. This is useful when you only want to vary a single option, while keeping all others consistent between parameter groups.</p>
</blockquote>
</blockquote>
<p><strong>Per-parameter option</strong><br>
æˆ‘ä¸ªäººç¿»è¯‘ä¸ºé€å‚æ•°é€‰é¡¹ã€‚<code>Optimizer</code>åœ¨æ„é€ çš„æ—¶å€™åŒæ ·æ”¯æŒå¯¹æ¯ä¸ªå‚æ•°è¿›è¡ŒæŒ‡å®šã€‚è¦å®ç°è¿™ç§åŠŸèƒ½ï¼Œæˆ‘ä»¬ä¸å†ä¼ å…¥ä¸€ä¸ªå«æœ‰<code>Variable</code>ç±»å‹å‚æ•°çš„<code>iterable</code>å¯¹è±¡ï¼Œè€Œæ˜¯ä¼ å…¥ä¸€ä¸ª<code>dict</code>å­—å…¸ç±»å‹çš„<code>iterable</code>å¯¹è±¡ã€‚æ¯ä¸ªå­—å…¸éƒ½å®šä¹‰äº†ä¸€ä¸ªå‚æ•°ç»„ï¼Œè¯¥å‚æ•°ç»„çš„keyå€¼æ˜¯&quot;params&quot;ï¼Œè€Œå¯¹åº”çš„å€¼ä¸ºä¸€ä¸ªåŒ…å«å‚æ•°çš„åˆ—è¡¨ã€‚åŒæ ·çš„å¯ä»¥åˆ©ç”¨å­—å…¸çš„é”®å€¼å¯¹<code>Optimizer</code>çš„å…¶ä»–å‚æ•°è¿›è¡ŒæŒ‡å®šï¼Œä½†æ˜¯keyå¿…é¡»ä¸<code>Optimizer</code>æ„é€ å™¨ä¼ å‚æ—¶çš„å…³é”®å­—ä¸€è‡´ã€‚è¿™äº›æŒ‡å®šçš„<code>Optimizer</code>çš„å‚æ•°ä¼šè¢«å•ç‹¬åº”ç”¨äºè¯¥å­—å…¸ä¸­çš„<code>params</code>è¿™äº›å‚æ•°ã€‚<br>
<strong>æ³¨æ„</strong>ï¼šä½ ä»ç„¶å¯ä»¥åœ¨æ„é€ å™¨ä¸­ä»¥å…³é”®å­—æ–¹å¼ä¼ å…¥å‚æ•°ï¼Œè¿™äº›å‚æ•°å°†è¢«å½“åšé»˜è®¤å€¼ä½¿ç”¨ï¼Œå¦‚æœä¸€ç»„å‚æ•°æ²¡æœ‰overrideè¿™ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆå°±å°†è‡ªåŠ¨ä½¿ç”¨é»˜è®¤çš„å‚æ•°å€¼ã€‚<br>
ä»¥ä¸‹æ˜¯å®ä¾‹ï¼š</p>
<blockquote>
<p>For example, this is very useful when one wants to specify per-layer learning rates:</p>
<pre><code>optim.SGD([
               {'params': model.base.parameters()},
               {'params': model.classifier.parameters(), 'lr': 1e-3}
           ], lr=1e-2, momentum=0.9)
</code></pre></blockquote>
<blockquote>
<p>This means that model.base&rsquo;s parameters will use the default learning rate of 1e-2, model.classifier&rsquo;s parameters will use a learning rate of 1e-3, and a momentum of 0.9 will be used for all parameters.</p>
</blockquote>
<p>å¯¹äºä¸Šé¢è¿™ä¸ªä¾‹å­ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¼ å…¥äº†ä¸€ä¸ªdictçš„åˆ—è¡¨ã€‚åˆ—è¡¨ä¸­æœ‰ä¸¤ä¸ªdictï¼Œç¬¬ä¸€ä¸ªçš„<code>params</code>key å¯¹åº”çš„æ˜¯<code>model.base.parameters()</code>ï¼Œè€Œæ²¡æœ‰å¯¹<code>Optimizer</code>çš„å…¶ä»–å‚æ•°è¿›è¡Œå…·ä½“æŒ‡å®šã€‚ç¬¬äºŒä¸ªdictçš„<code>params</code>keyå¯¹åº”çš„æ˜¯<code>model.classifier.parameters()</code>ï¼Œæ­¤å¤–è¿˜æœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œè¯´æ˜äº†<code>lr</code>çš„å€¼ä¸º1e-3ã€‚è€Œåœ¨åˆ—è¡¨ä¹‹å¤–åŒæ—¶åˆä¼ å…¥äº†<code>lr=1e-2</code>,<code>momentum=0.9</code>ï¼Œè¿™ä¸¤ä¸ªå€¼å°†ä½œä¸ºé»˜è®¤å€¼æ¥ä½¿ç”¨ã€‚æ‰€ä»¥æ•´ä¸ª<code>Optimizer</code>ä¸­ï¼Œ<code>base's parameters</code>å°†ä½¿ç”¨é»˜è®¤çš„å­¦ä¹ ç‡<code>1e-2</code>,é»˜è®¤çš„åŠ¨é‡è¶…å‚æ•°<code>0.9</code>;è€Œ<code>classifier.parameters()</code>å°†ä½¿ç”¨å…¶dictä¸­æä¾›çš„å­¦ä¹ ç‡<code>1e-3</code>,<code>momentum</code>ä»ç„¶ä½¿ç”¨é»˜è®¤å€¼ã€‚</p>
<blockquote>
<h4 id="taking-an-optimization-step">Taking an optimization step</h4>
<p>All optimizers implement a <code>step()</code> method, that updates the parameters. It can be used in two ways:</p>
</blockquote>
<blockquote>
<h4 id="optimizerstep"><strong><code>optimizer.step()</code></strong></h4>
</blockquote>
<blockquote>
<p>This is a simplified version supported by most optimizers. The function can be called once the gradients are computed using e.g. backward().</p>
</blockquote>
<p><strong>é‡‡å–ä¼˜åŒ–æ­¥éª¤</strong><br>
æ‰€æœ‰çš„Optimizeréƒ½å®ç°äº†<code>step()</code>æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”¨äºæ›´æ–°å‚æ•°ã€‚å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼ä½¿ç”¨<code>.step()</code>è¿›è¡Œä¼˜åŒ–ï¼š</p>
<p>ç¬¬ä¸€ç§æ–¹å¼ï¼š<code>optimizer.step()</code><br>
è¯¥æ–¹æ³•æ˜¯ä¸€ä¸ªç®€åŒ–åçš„ç‰ˆæœ¬ï¼Œè¢«å¤§å¤šæ•°optimizeræ‰€æ”¯æŒã€‚è¯¥å‡½æ•°ä¸€èˆ¬åœ¨æ‰€æœ‰æ¢¯åº¦å€¼è¢«æ›´æ–°ï¼ˆæˆ–è€…è¢«è®¡ç®—ï¼‰åè¿›è¡Œè°ƒç”¨,å¦‚åœ¨<code>.backward()</code>åè¿›è¡Œè°ƒç”¨ã€‚</p>
<p>ä»¥ä¸‹æ˜¯ä¾‹å­ï¼š</p>
<blockquote>
<p>Example:</p>
<pre><code>for input, target in dataset:
   optimizer.zero_grad()
   output = model(input)
   loss = loss_fn(output, target)
   loss.backward()
   optimizer.step()
</code></pre></blockquote>
<blockquote>
<h4 id="optimizerstepclosure"><code>optimizer.step(closure)</code></h4>
</blockquote>
<blockquote>
<p>Some optimization algorithms such as Conjugate Gradient and LBFGS need to reevaluate the function multiple times, so you have to pass in a closure that allows them to recompute your model. The closure should clear the gradients, compute the loss, and return it.</p>
</blockquote>
<p>ç¬¬äºŒç§æ–¹å¼ï¼š<code>optimizer.step(closure)</code><br>
æœ‰ä¸€äº›ä¼˜åŒ–ç®—æ³•ä¾‹å¦‚<code>Conjugate Gradient</code>ï¼Œ<code>LBFGS</code>ç­‰éœ€è¦å¤šæ¬¡é‡æ–°è®¡ç®—å‡½æ•°ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªé—­åŒ…<code>closure</code>ï¼Œé—­åŒ…ä¸­åº”è¯¥å®ç°çš„æ“ä½œæœ‰ï¼šæ¸…é›¶æ¢¯åº¦ï¼Œè®¡ç®—æŸå¤±å¹¶è¿”å›ã€‚<br>
ä»¥ä¸‹æ˜¯ä¾‹å­ï¼š</p>
<blockquote>
<p>Example:</p>
<pre><code>for input, target in dataset:
   def closure():
       optimizer.zero_grad()
       output = model(input)
       loss = loss_fn(output, target)
       loss.backward()
       return loss
   optimizer.step(closure)
</code></pre></blockquote>
<p>å…·ä½“çš„å„ä¸ªä¼˜åŒ–ç®—æ³•çš„æ•°å­¦åŸç†åœ¨æ­¤ä¸è¡¨ï¼Œè¯¦å‚æ‰‹å†™çš„ç¬”è®°æœ¬ã€‚</p>
<h1 id="2-å¦‚ä½•è°ƒæ•´å­¦ä¹ ç‡">2 å¦‚ä½•è°ƒæ•´å­¦ä¹ ç‡</h1>
<p><code>torch.optim.lr_scheduler</code>æ¨¡å—ï¼Œæä¾›äº†ä¸€äº›æ ¹æ®è®­ç»ƒæ¬¡æ•°æ¥è°ƒæ•´å­¦ä¹ ç‡(learning rate)çš„æ–¹æ³•ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æˆ‘ä»¬ä¼šè®¾ç½®éšç€epochçš„å¢å¤§è€Œé€æ¸å‡å°å­¦ä¹ ç‡ï¼Œä»è€Œè¾¾åˆ°æ›´å¥½çš„è®­ç»ƒæ•ˆæœã€‚
è€Œ<code>torch.optim.lr_scheduler.ReduceLROnPlateau</code>æä¾›äº†ä¸€äº›åŸºäºè®­ç»ƒä¸­æŸäº›æµ‹é‡å€¼ä½¿å¾—å­¦ä¹ ç‡åŠ¨æ€ä¸‹é™çš„åŠæ³•ã€‚</p>
<p>å­¦ä¹ ç‡çš„è°ƒæ•´åº”è¯¥æ”¾åœ¨optimizeræ›´æ–°ä¹‹åï¼Œå‚è€ƒæ¨¡æ¿ï¼š</p>
<pre><code>define scheduler
for epoch in range(1000):
    train(...)
    validate(...)
    scheduler.step()
</code></pre><p><strong>æ³¨æ„</strong>ï¼š åœ¨PyTorch 1.1.0ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œå­¦ä¹ ç‡çš„è°ƒæ•´åº”è¯¥è¢«æ”¾åœ¨optimizeræ›´æ–°ä¹‹å‰ï¼Œå¦‚æœæˆ‘ä»¬1.1.0ä¹‹åä»ç„¶å°†å­¦ä¹ ç‡çš„è°ƒæ•´(å³<code>scheduler.step()</code>)æ”¾åœ¨optimizer&rsquo;s update(å³<code>optimizer.step</code>)ä¹‹å‰ï¼Œé‚£ä¹ˆlearning rate scheduleçš„ç¬¬ä¸€ä¸ªå€¼å°†è¢«è·³è¿‡ã€‚æ‰€ä»¥å¦‚æœæŸä¸ªä»£ç æ˜¯åœ¨1.1.0ä¹‹å‰çš„ç‰ˆæœ¬å¼€å‘ï¼Œç§»æ¤åˆ°é«˜ç‰ˆæœ¬è¿›è¡Œè¿è¡Œï¼Œå‘ç°æ•ˆæœå˜å·®ï¼Œå¯ä»¥æ£€æŸ¥æ˜¯å¦å°†<code>scheduler.step()</code>æ”¾åœ¨äº†<code>optimizer.step()</code>ä¹‹å‰ã€‚</p>
<blockquote>
<p>æ³¨ï¼šä»¥ä¸Šéƒ¨åˆ†å‚è€ƒå®˜æ–¹æ–‡æ¡£æ‰¹ç¤ºã€‚</p>
</blockquote>
<h2 id="21-torchoptimlr_schedulersteplr">2.1 <code>torch.optim.lr_scheduler.StepLR</code></h2>
<p>é¦–å…ˆè´´ä¸Šå®˜æ–¹æ–‡æ¡£ï¼š</p>
<blockquote>
<h3 id="torchoptimlr_schedulersteplroptimizer-step_size-gamma01-last_epoch-1-verbosefalse"><code>torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)</code></h3>
</blockquote>
<blockquote>
<p>Decays the learning rate of each parameter group by gamma every step_size epochs. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When last_epoch=-1, sets initial lr as lr.</p>
</blockquote>
<p><code>StepLR</code>å¯ä»¥æ ¹æ®è¶…å‚æ•°<code>gamma</code>æ¯éš”å›ºå®šçš„<code>step_size</code>å°±è¡°å‡<code>learning_rate</code>ä¸€æ¬¡ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œè¿™ç§å¯¹<code>learning_rate</code>çš„æ›´æ–°å¯ä»¥ä¸å¤–ç•Œçš„å…¶ä»–å˜åŒ–åŒæ—¶è¿›è¡Œã€‚å½“<code>last_epoch = -1</code>æ—¶ï¼Œå°†lrç½®ä¸ºåˆå§‹å€¼ã€‚</p>
<blockquote>
<p>Parameters</p>
<ul>
<li>optimizer (Optimizer) â€“ Wrapped optimizer.</li>
<li>step_size (int) â€“ Period of learning rate decay.</li>
<li>gamma (float) â€“ Multiplicative factor of learning rate decay. Default: 0.1.</li>
<li>last_epoch (int) â€“ The index of last epoch. Default: -1.</li>
<li>verbose (bool) â€“ If True, prints a message to stdout for each update. Default: False.</li>
</ul>
</blockquote>
<p>å‚æ•°è¯´æ˜</p>
<ul>
<li>optimizer(Optimizer) &mdash;&ndash;ç”¨äºæŒ‡å®šschedulerçš„åº”ç”¨å¯¹è±¡ã€‚</li>
<li>step_size(int)&mdash;&ndash;ç”¨äºæŒ‡å®šæ­¥é•¿ï¼Œå³å‡ æ¬¡è¿­ä»£ä¹‹åè¿›è¡Œä¸€æ¬¡decay</li>
<li>gamma(float)&mdash;&ndash;å­¦ä¹ ç‡è¡°å‡çš„ä¹˜æ³•å› å­ï¼Œé»˜è®¤å€¼ä¸º0.1</li>
<li>last_epoch(int)&mdash;&ndash;æ›´æ–°çš„è¾¹ç•Œindexï¼Œå½“ç­‰äºè¿™ä¸ªå€¼çš„æ—¶å€™ï¼Œé‡ç½®lrï¼Œé»˜è®¤ä¸º-1</li>
<li>verbose(bool)&mdash;&ndash;å¦‚æœä¸ºTrueï¼Œæ¯æ¬¡decayä¼šå‘stdoutè¾“å‡ºä¸€æ¡ä¿¡æ¯ã€‚é»˜è®¤ä¸ºfalse.</li>
</ul>
<p>ä»¥ä¸‹æ˜¯å®ä¾‹ï¼š</p>
<blockquote>
<p>Example</p>
<pre><code># Assuming optimizer uses lr = 0.05 for all groups
# lr = 0.05     if epoch &lt; 30
# lr = 0.005    if 30 &lt;= epoch &lt; 60
# lr = 0.0005   if 60 &lt;= epoch &lt; 90
# ...
scheduler = StepLR(optimizer, step_size=30, gamma=0.1)
for epoch in range(100):
    train(...)
    validate(...)
    scheduler.step()
</code></pre></blockquote>
<p>å¯è§:æ¯ç»è¿‡ä¸€ä¸ª<code>step_size</code>ï¼Œ</p>
<pre><code class="language-math" data-lang="math">lr = lr*gamma 
</code></pre>
</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/pytorch/">PyTorch</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
    integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
    integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
    integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.querySelector(`.article-content`));"></script>
<script>
var katex_config = {
    delimiters: 
    [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false}
    ]
};
</script>
<script defer src="https://cdn.bootcss.com/KaTeX/0.11.1/contrib/auto-render.min.js" onload="renderMathInElement(document.body,katex_config)"></script>

    
</article>

    <aside class="related-contents--wrapper">
    
    
</aside>


    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "codefmeister" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>


    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2022 Codefmeister
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="1.1.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true" style="display:none">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
            </main>
        </div>
        <script src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"
    integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin="anonymous"></script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<link rel="stylesheet" href="/css/highlight/light.min.css" media="(prefers-color-scheme: light)">
<link rel="stylesheet" href="/css/highlight/dark.min.css" media="(prefers-color-scheme: dark)">

    </body>
</html>
